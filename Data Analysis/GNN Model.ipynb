{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1362762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b4cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/ashvinee/Documents/Ferrato/Data/all_ings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f206663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingg = pd.read_csv('/home/ashvinee/Documents/Ferrato/Data/all_ingredients_name.csv')\n",
    "col = list(ingg.In)\n",
    "cols = ['Dish Type','Title']+col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac9a70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashvinee/.local/share/virtualenvs/Ferrato-aimIbf9P/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999,3000,3001,3002,3003,3004,3005,3006,3007,3008,3009,3010,3011,3012,3013,3014,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3035,3036,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,3051,3052,3053,3054,3055,3056,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3149,3150,3151,3152,3153,3154,3155,3156,3157,3158,3159,3160,3161,3162,3163,3164,3165,3166,3167,3168,3169,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3194,3195,3196,3197,3198,3199,3200,3201,3202,3203,3204,3205,3206,3207,3208,3209,3210,3211,3212,3213,3214,3215,3216,3217,3218,3219,3220,3221,3222,3223,3224,3225,3226,3227,3228,3229,3230,3231,3232,3233,3234,3235,3236,3237,3238,3239,3240,3241,3242,3243,3244,3245,3246,3247,3248,3249,3250,3251,3252,3253,3254,3255,3256,3257,3258,3259,3260,3261,3262,3263,3264,3265,3266,3267,3268,3269,3270,3271,3272,3273,3274,3275,3276,3277,3278,3279,3280,3281,3282,3283,3284,3285,3286,3287,3288,3289,3290,3291,3292,3293,3294,3295,3296,3297,3298,3299,3300,3301,3302,3303,3304,3305,3306,3307,3308,3309,3310,3311,3312,3313,3314,3315,3316,3317,3318,3319,3320,3321,3322,3323,3324,3325,3326,3327,3328,3329,3330,3331,3332,3333,3334,3335,3336,3337,3338,3339,3340,3341,3342,3343,3344,3345,3346,3347,3348,3349,3350,3351,3352,3353,3354,3355,3356,3357,3358,3359,3360,3361,3362,3363,3364,3365,3366,3367,3368,3369,3370,3371,3372,3373,3374,3375,3376,3377,3378,3379,3380,3381,3382,3383,3384,3385,3386,3387,3388,3389,3390,3391,3392,3393,3394,3395,3396,3397,3398,3399,3400,3401,3402,3403,3404,3405,3406,3407,3408,3409,3410,3411,3412,3413,3414,3415,3416,3417,3418,3419,3420,3421,3422,3423,3424,3425,3426,3427,3428,3429,3430,3431,3432,3433,3434,3435,3436,3437,3438,3439,3440,3441,3442,3443,3444,3445,3446,3447,3448,3449,3450,3451,3452,3453,3454,3455,3456,3457,3458,3459,3460,3461,3462,3463,3464,3465,3466,3467,3468,3469,3470,3471,3472,3473,3474,3475,3476,3477,3478,3479,3480,3481,3482,3483,3484,3485,3486,3487,3488,3489,3490,3491,3492,3493,3494,3495,3496,3497,3498,3499,3500,3501,3502,3503,3504) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "citations = pd.read_csv(\n",
    "    \"/home/ashvinee/Documents/Ferrato/Data/breakfast_ingredients_835_final6.csv\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    "    names=cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a459cecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Dish Type</th>\n",
       "      <th>Title</th>\n",
       "      <th>salt</th>\n",
       "      <th>pepper</th>\n",
       "      <th>butter</th>\n",
       "      <th>garlic</th>\n",
       "      <th>sugar</th>\n",
       "      <th>flour</th>\n",
       "      <th>onion</th>\n",
       "      <th>olive oil</th>\n",
       "      <th>...</th>\n",
       "      <th>cooked meatballs</th>\n",
       "      <th>beef sausage</th>\n",
       "      <th>mulberries</th>\n",
       "      <th>fine egg noodles</th>\n",
       "      <th>linguica</th>\n",
       "      <th>poblano chilies</th>\n",
       "      <th>crystal hot sauce</th>\n",
       "      <th>watercress leaves</th>\n",
       "      <th>emerils essence</th>\n",
       "      <th>corn flakes cereal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <th>Total Ing</th>\n",
       "      <th>index</th>\n",
       "      <td>Dish Type</td>\n",
       "      <td>Title</td>\n",
       "      <td>salt</td>\n",
       "      <td>pepper</td>\n",
       "      <td>butter</td>\n",
       "      <td>garlic</td>\n",
       "      <td>sugar</td>\n",
       "      <td>flour</td>\n",
       "      <td>onion</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>...</td>\n",
       "      <td>cooked meatballs</td>\n",
       "      <td>beef sausage</td>\n",
       "      <td>mulberries</td>\n",
       "      <td>fine egg noodles</td>\n",
       "      <td>linguica</td>\n",
       "      <td>poblano chilies</td>\n",
       "      <td>crystal hot sauce</td>\n",
       "      <td>watercress leaves</td>\n",
       "      <td>emerils essence</td>\n",
       "      <td>corn flakes cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>22</th>\n",
       "      <th>0.0</th>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>64</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <th>58</th>\n",
       "      <th>2.0</th>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <th>22</th>\n",
       "      <th>3.0</th>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850.0</th>\n",
       "      <th>13</th>\n",
       "      <th>849.0</th>\n",
       "      <td>1</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851.0</th>\n",
       "      <th>43</th>\n",
       "      <th>850.0</th>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852.0</th>\n",
       "      <th>47</th>\n",
       "      <th>851.0</th>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853.0</th>\n",
       "      <th>32</th>\n",
       "      <th>852.0</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854.0</th>\n",
       "      <th>27</th>\n",
       "      <th>853.0</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>855 rows × 3502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Dish Type  Title  salt  pepper  butter  garlic  sugar  \\\n",
       "NaN   Total Ing index  Dish Type  Title  salt  pepper  butter  garlic  sugar   \n",
       "1.0   22        0.0            0    283     1       0       0       0      0   \n",
       "2.0   64        1.0            0    101     1       0       0       0      0   \n",
       "3.0   58        2.0            0    463     1       1       0       1      0   \n",
       "4.0   22        3.0            0    283     1       0       0       0      0   \n",
       "...                          ...    ...   ...     ...     ...     ...    ...   \n",
       "850.0 13        849.0          1    468     0       0       1       0      0   \n",
       "851.0 43        850.0          1    165     1       1       1       1      0   \n",
       "852.0 47        851.0          1    165     1       0       1       0      1   \n",
       "853.0 32        852.0          1    128     1       0       0       1      0   \n",
       "854.0 27        853.0          1    128     1       0       1       0      1   \n",
       "\n",
       "                       flour  onion  olive oil  ...  cooked meatballs  \\\n",
       "NaN   Total Ing index  flour  onion  olive oil  ...  cooked meatballs   \n",
       "1.0   22        0.0        0      0          0  ...                 0   \n",
       "2.0   64        1.0        0      1          0  ...                 0   \n",
       "3.0   58        2.0        0      0          0  ...                 0   \n",
       "4.0   22        3.0        0      0          0  ...                 0   \n",
       "...                      ...    ...        ...  ...               ...   \n",
       "850.0 13        849.0      1      0          0  ...                 0   \n",
       "851.0 43        850.0      0      1          0  ...                 0   \n",
       "852.0 47        851.0      1      0          0  ...                 0   \n",
       "853.0 32        852.0      0      0          0  ...                 0   \n",
       "854.0 27        853.0      1      0          0  ...                 0   \n",
       "\n",
       "                       beef sausage  mulberries  fine egg noodles  linguica  \\\n",
       "NaN   Total Ing index  beef sausage  mulberries  fine egg noodles  linguica   \n",
       "1.0   22        0.0               0           0                 0         0   \n",
       "2.0   64        1.0               0           0                 0         0   \n",
       "3.0   58        2.0               0           0                 0         0   \n",
       "4.0   22        3.0               0           0                 0         0   \n",
       "...                             ...         ...               ...       ...   \n",
       "850.0 13        849.0             0           0                 0         0   \n",
       "851.0 43        850.0             0           0                 0         0   \n",
       "852.0 47        851.0             0           0                 0         0   \n",
       "853.0 32        852.0             0           0                 0         0   \n",
       "854.0 27        853.0             0           0                 0         0   \n",
       "\n",
       "                       poblano chilies  crystal hot sauce  watercress leaves  \\\n",
       "NaN   Total Ing index  poblano chilies  crystal hot sauce  watercress leaves   \n",
       "1.0   22        0.0                  0                  0                  0   \n",
       "2.0   64        1.0                  0                  0                  0   \n",
       "3.0   58        2.0                  0                  0                  0   \n",
       "4.0   22        3.0                  0                  0                  0   \n",
       "...                                ...                ...                ...   \n",
       "850.0 13        849.0                0                  0                  0   \n",
       "851.0 43        850.0                0                  0                  0   \n",
       "852.0 47        851.0                0                  0                  0   \n",
       "853.0 32        852.0                0                  0                  0   \n",
       "854.0 27        853.0                0                  0                  0   \n",
       "\n",
       "                       emerils essence  corn flakes cereal  \n",
       "NaN   Total Ing index  emerils essence  corn flakes cereal  \n",
       "1.0   22        0.0                  0                   0  \n",
       "2.0   64        1.0                  0                   0  \n",
       "3.0   58        2.0                  0                   0  \n",
       "4.0   22        3.0                  0                   0  \n",
       "...                                ...                 ...  \n",
       "850.0 13        849.0                0                   0  \n",
       "851.0 43        850.0                0                   0  \n",
       "852.0 47        851.0                0                   0  \n",
       "853.0 32        852.0                0                   0  \n",
       "854.0 27        853.0                0                   0  \n",
       "\n",
       "[855 rows x 3502 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e87c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = citations.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412f7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = citations.drop(citations.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7ba455",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = citations.drop('level_0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38643af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = citations.drop('level_1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72306c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = citations.drop('level_2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3bab401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#citations = citations.drop('Dish Type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eee87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = citations.Title.values\n",
    "citations = citations.drop('Title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3767e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# citations.index = citations.index.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80bfc29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = citations.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31b987a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee7b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa = [int(i) for i in cc[0]]\n",
    "# ar = np.array([sa])\n",
    "\n",
    "# for sa in range(1,cc.shape[0]):\n",
    "#     ll = [int(i) for i in cc[sa]]\n",
    "#     ar = np.append(ar, [ll], axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f511f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(854, 3501)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07715ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp.csr_matrix(cc, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471244d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<854x3501 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 21743 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8bae33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91c2c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = encode_onehot(cc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0222117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5637f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = title.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7420238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build graph\n",
    "idx = np.array(title, dtype=np.int32)\n",
    "idx_map = {j: i for i, j in enumerate(idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b56d955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset), dtype=np.int32)\n",
    "edges_unordered = pd.read_csv(\n",
    "    \"/home/ashvinee/Documents/Ferrato/Data/similar_ingredients.csv\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    "    names=['FTitle', 'STitle', 'Sting'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "690e5d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTitle</th>\n",
       "      <th>STitle</th>\n",
       "      <th>Sting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>FTitle</td>\n",
       "      <td>STitle</td>\n",
       "      <td>Sting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>283</td>\n",
       "      <td>239</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>283</td>\n",
       "      <td>310</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>283</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>283</td>\n",
       "      <td>251</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253.0</th>\n",
       "      <td>292</td>\n",
       "      <td>193</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254.0</th>\n",
       "      <td>292</td>\n",
       "      <td>190</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255.0</th>\n",
       "      <td>292</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256.0</th>\n",
       "      <td>292</td>\n",
       "      <td>75</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257.0</th>\n",
       "      <td>292</td>\n",
       "      <td>435</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FTitle  STitle  Sting\n",
       "NaN    FTitle  STitle  Sting\n",
       "1.0       283     239     22\n",
       "2.0       283     310     22\n",
       "4.0       283      66     22\n",
       "5.0       283     251     22\n",
       "...       ...     ...    ...\n",
       "253.0     292     193     17\n",
       "254.0     292     190     17\n",
       "255.0     292      37     17\n",
       "256.0     292      75     17\n",
       "257.0     292     435     17\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_unordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "702185df",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_unordered = edges_unordered.reset_index()\n",
    "edges_unordered = edges_unordered.drop('index', axis=1)\n",
    "edges_unordered = edges_unordered.drop(index=0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68cce407",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_unordered = edges_unordered.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4f504b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20318653",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48bb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6747f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build symmetric adjacency matrix\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55c3b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71d7fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = normalize(features)\n",
    "# adj = normalize(adj + sp.eye(adj.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1f581c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<854x3501 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 21743 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "198425d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = range(140)\n",
    "idx_val = range(200, 500)\n",
    "idx_test = range(500, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9534b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21ef20fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<854x3501 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 21743 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f024ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "labels = torch.LongTensor(np.where(labels)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40616f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = torch.FloatTensor(np.array(features.todense()))\n",
    "# adj = sparse_mx_to_torch_sparse_tensor(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f574aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sparse_mx_to_torch_sparse_tensor(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5048de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = torch.LongTensor(idx_train)\n",
    "idx_val = torch.LongTensor(idx_val)\n",
    "idx_test = torch.LongTensor(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7206133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return adj, features, labels, idx_train, idx_val, idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60710a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([], size=(1, 0)),\n",
       "       values=tensor([], size=(0,)),\n",
       "       size=(854,), nnz=0, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea672cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor(indices=tensor([[   0,    8,   14,  ..., 1389, 2344, 2707],\n",
    "#                        [   0,    0,    0,  ..., 2707, 2707, 2707]]),\n",
    "#        values=tensor([0.1667, 0.1667, 0.0500,  ..., 0.2000, 0.5000, 0.2500]),\n",
    "#        size=(2708, 2708), nnz=13264, layout=torch.sparse_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bbc2717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03ca9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         ...,\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "#         [0., 0., 0.,  ..., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19ffc447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc60f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([5, 3, 4,  ..., 0, 6, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41ff7942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2080126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
    "#          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
    "#          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
    "#          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
    "#          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
    "#          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
    "#          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
    "#          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
    "#         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
    "#         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa9b4949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
       "        214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
       "        228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
       "        242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
       "        256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
       "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
       "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
       "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
       "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
       "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
       "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
       "        382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
       "        396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
       "        410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
       "        424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
       "        438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451,\n",
       "        452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "        466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
       "        480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "        494, 495, 496, 497, 498, 499])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "409dd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
    "#         214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
    "#         228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
    "#         242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
    "#         256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
    "#         270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
    "#         284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
    "#         298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
    "#         312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
    "#         326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
    "#         340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
    "#         354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
    "#         368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
    "#         382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
    "#         396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
    "#         410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
    "#         424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
    "#         438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451,\n",
    "#         452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
    "#         466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
    "#         480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
    "#         494, 495, 496, 497, 498, 499])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db6a1b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 500,  501,  502,  503,  504,  505,  506,  507,  508,  509,  510,  511,\n",
       "         512,  513,  514,  515,  516,  517,  518,  519,  520,  521,  522,  523,\n",
       "         524,  525,  526,  527,  528,  529,  530,  531,  532,  533,  534,  535,\n",
       "         536,  537,  538,  539,  540,  541,  542,  543,  544,  545,  546,  547,\n",
       "         548,  549,  550,  551,  552,  553,  554,  555,  556,  557,  558,  559,\n",
       "         560,  561,  562,  563,  564,  565,  566,  567,  568,  569,  570,  571,\n",
       "         572,  573,  574,  575,  576,  577,  578,  579,  580,  581,  582,  583,\n",
       "         584,  585,  586,  587,  588,  589,  590,  591,  592,  593,  594,  595,\n",
       "         596,  597,  598,  599,  600,  601,  602,  603,  604,  605,  606,  607,\n",
       "         608,  609,  610,  611,  612,  613,  614,  615,  616,  617,  618,  619,\n",
       "         620,  621,  622,  623,  624,  625,  626,  627,  628,  629,  630,  631,\n",
       "         632,  633,  634,  635,  636,  637,  638,  639,  640,  641,  642,  643,\n",
       "         644,  645,  646,  647,  648,  649,  650,  651,  652,  653,  654,  655,\n",
       "         656,  657,  658,  659,  660,  661,  662,  663,  664,  665,  666,  667,\n",
       "         668,  669,  670,  671,  672,  673,  674,  675,  676,  677,  678,  679,\n",
       "         680,  681,  682,  683,  684,  685,  686,  687,  688,  689,  690,  691,\n",
       "         692,  693,  694,  695,  696,  697,  698,  699,  700,  701,  702,  703,\n",
       "         704,  705,  706,  707,  708,  709,  710,  711,  712,  713,  714,  715,\n",
       "         716,  717,  718,  719,  720,  721,  722,  723,  724,  725,  726,  727,\n",
       "         728,  729,  730,  731,  732,  733,  734,  735,  736,  737,  738,  739,\n",
       "         740,  741,  742,  743,  744,  745,  746,  747,  748,  749,  750,  751,\n",
       "         752,  753,  754,  755,  756,  757,  758,  759,  760,  761,  762,  763,\n",
       "         764,  765,  766,  767,  768,  769,  770,  771,  772,  773,  774,  775,\n",
       "         776,  777,  778,  779,  780,  781,  782,  783,  784,  785,  786,  787,\n",
       "         788,  789,  790,  791,  792,  793,  794,  795,  796,  797,  798,  799,\n",
       "         800,  801,  802,  803,  804,  805,  806,  807,  808,  809,  810,  811,\n",
       "         812,  813,  814,  815,  816,  817,  818,  819,  820,  821,  822,  823,\n",
       "         824,  825,  826,  827,  828,  829,  830,  831,  832,  833,  834,  835,\n",
       "         836,  837,  838,  839,  840,  841,  842,  843,  844,  845,  846,  847,\n",
       "         848,  849,  850,  851,  852,  853,  854,  855,  856,  857,  858,  859,\n",
       "         860,  861,  862,  863,  864,  865,  866,  867,  868,  869,  870,  871,\n",
       "         872,  873,  874,  875,  876,  877,  878,  879,  880,  881,  882,  883,\n",
       "         884,  885,  886,  887,  888,  889,  890,  891,  892,  893,  894,  895,\n",
       "         896,  897,  898,  899,  900,  901,  902,  903,  904,  905,  906,  907,\n",
       "         908,  909,  910,  911,  912,  913,  914,  915,  916,  917,  918,  919,\n",
       "         920,  921,  922,  923,  924,  925,  926,  927,  928,  929,  930,  931,\n",
       "         932,  933,  934,  935,  936,  937,  938,  939,  940,  941,  942,  943,\n",
       "         944,  945,  946,  947,  948,  949,  950,  951,  952,  953,  954,  955,\n",
       "         956,  957,  958,  959,  960,  961,  962,  963,  964,  965,  966,  967,\n",
       "         968,  969,  970,  971,  972,  973,  974,  975,  976,  977,  978,  979,\n",
       "         980,  981,  982,  983,  984,  985,  986,  987,  988,  989,  990,  991,\n",
       "         992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1002, 1003,\n",
       "        1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015,\n",
       "        1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027,\n",
       "        1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039,\n",
       "        1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051,\n",
       "        1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063,\n",
       "        1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075,\n",
       "        1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087,\n",
       "        1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099,\n",
       "        1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111,\n",
       "        1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123,\n",
       "        1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135,\n",
       "        1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147,\n",
       "        1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159,\n",
       "        1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171,\n",
       "        1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183,\n",
       "        1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195,\n",
       "        1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207,\n",
       "        1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219,\n",
       "        1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231,\n",
       "        1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243,\n",
       "        1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255,\n",
       "        1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267,\n",
       "        1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279,\n",
       "        1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291,\n",
       "        1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303,\n",
       "        1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315,\n",
       "        1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327,\n",
       "        1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339,\n",
       "        1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351,\n",
       "        1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363,\n",
       "        1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375,\n",
       "        1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387,\n",
       "        1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399,\n",
       "        1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411,\n",
       "        1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423,\n",
       "        1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435,\n",
       "        1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447,\n",
       "        1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459,\n",
       "        1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471,\n",
       "        1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483,\n",
       "        1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495,\n",
       "        1496, 1497, 1498, 1499])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddc2d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([ 500,  501,  502,  503,  504,  505,  506,  507,  508,  509,  510,  511,\n",
    "#          512,  513,  514,  515,  516,  517,  518,  519,  520,  521,  522,  523,\n",
    "#          524,  525,  526,  527,  528,  529,  530,  531,  532,  533,  534,  535,\n",
    "#          536,  537,  538,  539,  540,  541,  542,  543,  544,  545,  546,  547,\n",
    "#          548,  549,  550,  551,  552,  553,  554,  555,  556,  557,  558,  559,\n",
    "#          560,  561,  562,  563,  564,  565,  566,  567,  568,  569,  570,  571,\n",
    "#          572,  573,  574,  575,  576,  577,  578,  579,  580,  581,  582,  583,\n",
    "#          584,  585,  586,  587,  588,  589,  590,  591,  592,  593,  594,  595,\n",
    "#          596,  597,  598,  599,  600,  601,  602,  603,  604,  605,  606,  607,\n",
    "#          608,  609,  610,  611,  612,  613,  614,  615,  616,  617,  618,  619,\n",
    "#          620,  621,  622,  623,  624,  625,  626,  627,  628,  629,  630,  631,\n",
    "#          632,  633,  634,  635,  636,  637,  638,  639,  640,  641,  642,  643,\n",
    "#          644,  645,  646,  647,  648,  649,  650,  651,  652,  653,  654,  655,\n",
    "#          656,  657,  658,  659,  660,  661,  662,  663,  664,  665,  666,  667,\n",
    "#          668,  669,  670,  671,  672,  673,  674,  675,  676,  677,  678,  679,\n",
    "#          680,  681,  682,  683,  684,  685,  686,  687,  688,  689,  690,  691,\n",
    "#          692,  693,  694,  695,  696,  697,  698,  699,  700,  701,  702,  703,\n",
    "#          704,  705,  706,  707,  708,  709,  710,  711,  712,  713,  714,  715,\n",
    "#          716,  717,  718,  719,  720,  721,  722,  723,  724,  725,  726,  727,\n",
    "#          728,  729,  730,  731,  732,  733,  734,  735,  736,  737,  738,  739,\n",
    "#          740,  741,  742,  743,  744,  745,  746,  747,  748,  749,  750,  751,\n",
    "#          752,  753,  754,  755,  756,  757,  758,  759,  760,  761,  762,  763,\n",
    "#          764,  765,  766,  767,  768,  769,  770,  771,  772,  773,  774,  775,\n",
    "#          776,  777,  778,  779,  780,  781,  782,  783,  784,  785,  786,  787,\n",
    "#          788,  789,  790,  791,  792,  793,  794,  795,  796,  797,  798,  799,\n",
    "#          800,  801,  802,  803,  804,  805,  806,  807,  808,  809,  810,  811,\n",
    "#          812,  813,  814,  815,  816,  817,  818,  819,  820,  821,  822,  823,\n",
    "#          824,  825,  826,  827,  828,  829,  830,  831,  832,  833,  834,  835,\n",
    "#          836,  837,  838,  839,  840,  841,  842,  843,  844,  845,  846,  847,\n",
    "#          848,  849,  850,  851,  852,  853,  854,  855,  856,  857,  858,  859,\n",
    "#          860,  861,  862,  863,  864,  865,  866,  867,  868,  869,  870,  871,\n",
    "#          872,  873,  874,  875,  876,  877,  878,  879,  880,  881,  882,  883,\n",
    "#          884,  885,  886,  887,  888,  889,  890,  891,  892,  893,  894,  895,\n",
    "#          896,  897,  898,  899,  900,  901,  902,  903,  904,  905,  906,  907,\n",
    "#          908,  909,  910,  911,  912,  913,  914,  915,  916,  917,  918,  919,\n",
    "#          920,  921,  922,  923,  924,  925,  926,  927,  928,  929,  930,  931,\n",
    "#          932,  933,  934,  935,  936,  937,  938,  939,  940,  941,  942,  943,\n",
    "#          944,  945,  946,  947,  948,  949,  950,  951,  952,  953,  954,  955,\n",
    "#          956,  957,  958,  959,  960,  961,  962,  963,  964,  965,  966,  967,\n",
    "#          968,  969,  970,  971,  972,  973,  974,  975,  976,  977,  978,  979,\n",
    "#          980,  981,  982,  983,  984,  985,  986,  987,  988,  989,  990,  991,\n",
    "#          992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1002, 1003,\n",
    "#         1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015,\n",
    "#         1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027,\n",
    "#         1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039,\n",
    "#         1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051,\n",
    "#         1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063,\n",
    "#         1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075,\n",
    "#         1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087,\n",
    "#         1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099,\n",
    "#         1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111,\n",
    "#         1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123,\n",
    "#         1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135,\n",
    "#         1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147,\n",
    "#         1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159,\n",
    "#         1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171,\n",
    "#         1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183,\n",
    "#         1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195,\n",
    "#         1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207,\n",
    "#         1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219,\n",
    "#         1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231,\n",
    "#         1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243,\n",
    "#         1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255,\n",
    "#         1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267,\n",
    "#         1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279,\n",
    "#         1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291,\n",
    "#         1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303,\n",
    "#         1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315,\n",
    "#         1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327,\n",
    "#         1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339,\n",
    "#         1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351,\n",
    "#         1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363,\n",
    "#         1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375,\n",
    "#         1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387,\n",
    "#         1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399,\n",
    "#         1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411,\n",
    "#         1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423,\n",
    "#         1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435,\n",
    "#         1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447,\n",
    "#         1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459,\n",
    "#         1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471,\n",
    "#         1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483,\n",
    "#         1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495,\n",
    "#         1496, 1497, 1498, 1499])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8cfb7baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9792f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "#from utils import load_data, accuracy\n",
    "#from models import GCN\n",
    "#from onnix_food import export_onnix, ColaPredictor\n",
    "#import wandb\n",
    "import os\n",
    "#import hydra\n",
    "#from omegaconf import OmegaConf\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from layers import GraphConvolution\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8bcfa77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "#cfg.training.cuda = not cfg.processing.no_cuda and torch.cuda.is_available()\n",
    "if False:\n",
    "    torch.cuda.manual_seed(cfg.training.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5051549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ffb30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dbad057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=16,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53b1f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gc1): GraphConvolution (3501 -> 16)\n",
       "  (gc2): GraphConvolution (16 -> 2)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f00382ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/ashvinee/.local/share/virtualenvs/Ferrato-aimIbf9P/lib/python3.8/site-packages (1.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebf6445a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([854, 854])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4781c05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([854, 3501])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e13f50a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(model, input_size=(3501,16,3501), input_size=(3501,16,3501))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "22f31096",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.1, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5d53693",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4109fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "def train(model, optimizer, scheduler, adj, features, labels, idx_train, idx_val):\n",
    "    t_total = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(20):\n",
    "        #train(epoch)\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features, adj)\n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        if not False:\n",
    "            # Evaluate validation set performance separately,\n",
    "            # deactivates dropout during validation run.\n",
    "            model.eval()\n",
    "            output = model(features, adj)\n",
    "\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "\n",
    "        if acc_val > best_acc:\n",
    "            best_acc = acc_val\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print('Epoch: {:04d}'.format(epoch + 1),\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "        \n",
    "        time_elapsed = time.time() - t_total\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26e6dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c20aa463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 5.1037 acc_train: 0.6643 loss_val: 10.5347 acc_val: 0.0000 time: 0.0448s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0002 loss_train: 0.4400 acc_train: 0.9714 loss_val: 17.5512 acc_val: 0.0000 time: 0.0099s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0003 loss_train: 0.9843 acc_train: 0.9714 loss_val: 22.8118 acc_val: 0.0000 time: 0.0068s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0004 loss_train: 1.2179 acc_train: 0.9714 loss_val: 26.0285 acc_val: 0.0000 time: 0.0057s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0005 loss_train: 1.5536 acc_train: 0.9714 loss_val: 27.0566 acc_val: 0.0000 time: 0.0109s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0006 loss_train: 1.0680 acc_train: 0.9714 loss_val: 26.9083 acc_val: 0.0000 time: 0.0052s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0007 loss_train: 1.7013 acc_train: 0.9714 loss_val: 25.0974 acc_val: 0.0000 time: 0.0051s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0008 loss_train: 0.8581 acc_train: 0.9714 loss_val: 22.4255 acc_val: 0.0000 time: 0.0090s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0009 loss_train: 0.7594 acc_train: 0.9714 loss_val: 19.1563 acc_val: 0.0000 time: 0.0078s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0010 loss_train: 1.0050 acc_train: 0.9714 loss_val: 15.2496 acc_val: 0.0000 time: 0.0079s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0011 loss_train: 0.5568 acc_train: 0.9571 loss_val: 12.2027 acc_val: 0.0000 time: 0.0064s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0012 loss_train: 0.1859 acc_train: 0.9571 loss_val: 10.0062 acc_val: 0.0000 time: 0.0046s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0013 loss_train: 2.9484 acc_train: 0.9000 loss_val: 11.9690 acc_val: 0.0000 time: 0.0046s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0014 loss_train: 0.6116 acc_train: 0.9714 loss_val: 13.3481 acc_val: 0.0000 time: 0.0045s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0015 loss_train: 0.5534 acc_train: 0.9714 loss_val: 14.3153 acc_val: 0.0000 time: 0.0048s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0016 loss_train: 0.5687 acc_train: 0.9714 loss_val: 14.8814 acc_val: 0.0000 time: 0.0044s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0017 loss_train: 0.1650 acc_train: 0.9714 loss_val: 15.3219 acc_val: 0.0000 time: 0.0044s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0018 loss_train: 0.1917 acc_train: 0.9714 loss_val: 15.6398 acc_val: 0.0000 time: 0.0045s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0019 loss_train: 0.4274 acc_train: 0.9714 loss_val: 15.6852 acc_val: 0.0000 time: 0.0045s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n",
      "Epoch: 0020 loss_train: 0.1844 acc_train: 0.9714 loss_val: 15.6188 acc_val: 0.0000 time: 0.0043s\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft, loss = train(model, optimizer, exp_lr_scheduler, adj, features, labels, idx_train, idx_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a672653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc1.weight Parameter containing:\n",
      "tensor([[ 0.1911,  0.2075, -0.0586,  ...,  0.0339,  0.1205, -0.0353],\n",
      "        [ 0.1927,  0.0370, -0.1167,  ..., -0.2469,  0.2258, -0.2124],\n",
      "        [ 0.1930,  0.0416, -0.0812,  ..., -0.1093,  0.1443,  0.0447],\n",
      "        ...,\n",
      "        [-0.1698, -0.0045, -0.1219,  ..., -0.0332, -0.1029, -0.2023],\n",
      "        [-0.0655,  0.1893,  0.0871,  ...,  0.0358, -0.1784,  0.1259],\n",
      "        [ 0.2226, -0.1175, -0.2049,  ...,  0.0851,  0.0107,  0.2146]],\n",
      "       requires_grad=True)\n",
      "gc1.bias Parameter containing:\n",
      "tensor([ 0.2035,  0.0199,  0.2153,  0.0877,  0.0459, -0.0409, -0.0520, -0.0142,\n",
      "         0.0124, -0.0377,  0.0293,  0.1532,  0.1146, -0.1783,  0.1550,  0.0816],\n",
      "       requires_grad=True)\n",
      "gc2.weight Parameter containing:\n",
      "tensor([[ 0.0308, -0.3458],\n",
      "        [-0.2816,  0.0041],\n",
      "        [ 0.1889, -0.7018],\n",
      "        [-0.2627,  0.1501],\n",
      "        [ 0.3917, -0.3956],\n",
      "        [-0.3303, -0.0182],\n",
      "        [ 0.3845,  0.5243],\n",
      "        [-0.6911,  0.6710],\n",
      "        [ 0.0750, -0.6707],\n",
      "        [-0.1778,  0.1889],\n",
      "        [-0.2569, -0.6830],\n",
      "        [-0.4985,  0.3839],\n",
      "        [-0.2016, -0.4170],\n",
      "        [ 0.2278, -0.0015],\n",
      "        [ 0.3211,  0.5381],\n",
      "        [-0.5019,  0.3781]], requires_grad=True)\n",
      "gc2.bias Parameter containing:\n",
      "tensor([ 0.6895, -0.1164], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f432c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([854, 2])\n",
      "tensor([[-0.3693, -1.1751],\n",
      "        [-0.3693, -1.1751],\n",
      "        [-0.3693, -1.1751],\n",
      "        ...,\n",
      "        [-0.3693, -1.1751],\n",
      "        [-0.3693, -1.1751],\n",
      "        [-0.3693, -1.1751]], grad_fn=<LogSoftmaxBackward>)\n",
      "Test set results: loss= 1.1010 accuracy= 0.1102\n"
     ]
    }
   ],
   "source": [
    "#def test(model, adj, features, labels, idx_test):\n",
    "model.eval()\n",
    "output = model(features, adj)\n",
    "print(output.shape)\n",
    "print(output)\n",
    "loss_test = F.nll_loss(output[idx_test[:354]], labels[idx_test[:354]])\n",
    "acc_test = accuracy(output[idx_test[:354]], labels[idx_test[:354]])\n",
    "\n",
    "\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(loss_test.item()),\n",
    "      \"accuracy= {:.4f}\".format(acc_test.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1940bf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([854, 3501])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37de668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386ed1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6e088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f4b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14273c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salt, egg, oil, rice, chile, onion\n"
     ]
    }
   ],
   "source": [
    "aab = input().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b5d10a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt', ' egg', ' oil', ' rice', ' chile', ' onion']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e87cd19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([854, 3501])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "71f70026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt',\n",
       " 'pepper',\n",
       " 'butter',\n",
       " 'garlic',\n",
       " 'sugar',\n",
       " 'flour',\n",
       " 'onion',\n",
       " 'olive oil',\n",
       " 'water',\n",
       " 'ground',\n",
       " 'olive',\n",
       " 'powder',\n",
       " 'sliced',\n",
       " 'eggs',\n",
       " 'black pepper',\n",
       " 'milk',\n",
       " 'cheese',\n",
       " 'cream',\n",
       " 'lemon',\n",
       " 'chicken',\n",
       " 'sauce',\n",
       " 'tomatoes',\n",
       " 'brown',\n",
       " 'white',\n",
       " 'egg',\n",
       " 'onions',\n",
       " 'vinegar',\n",
       " 'vegetable',\n",
       " 'brown sugar',\n",
       " 'lemon juice',\n",
       " 'ground black pepper',\n",
       " 'parsley',\n",
       " 'cinnamon',\n",
       " 'garlic cloves',\n",
       " 'extract',\n",
       " 'vegetable oil',\n",
       " 'vanilla',\n",
       " 'baking powder',\n",
       " 'vanilla extract',\n",
       " 'unsalted butter',\n",
       " 'ginger',\n",
       " 'chocolate',\n",
       " 'leaves',\n",
       " 'soda',\n",
       " 'parmesan',\n",
       " 'tomato',\n",
       " 'celery',\n",
       " 'potatoes',\n",
       " 'kosher salt',\n",
       " 'mustard',\n",
       " 'cheddar',\n",
       " 'juice',\n",
       " 'baking soda',\n",
       " 'kosher',\n",
       " 'sour cream',\n",
       " 'cilantro',\n",
       " 'soy sauce',\n",
       " 'cream cheese',\n",
       " 'parmesan cheese',\n",
       " 'cheddar cheese',\n",
       " 'oregano',\n",
       " 'red pepper',\n",
       " 'carrots',\n",
       " 'clove',\n",
       " 'chicken broth',\n",
       " 'mushrooms',\n",
       " 'honey',\n",
       " 'packed',\n",
       " 'orange',\n",
       " 'bread',\n",
       " 'thyme',\n",
       " 'oil',\n",
       " 'basil',\n",
       " 'seasoning',\n",
       " 'extra',\n",
       " 'margarine',\n",
       " 'mayonnaise',\n",
       " 'bell pepper',\n",
       " 'cayenne',\n",
       " 'garlic powder',\n",
       " 'nutmeg',\n",
       " 'plus',\n",
       " 'cloves',\n",
       " 'garlic minced',\n",
       " 'white wine',\n",
       " 'bacon',\n",
       " 'peppers',\n",
       " 'ground cinnamon',\n",
       " 'heavy cream',\n",
       " 'boneless',\n",
       " 'garnish',\n",
       " 'paprika',\n",
       " 'black',\n",
       " 'beans',\n",
       " 'toasted',\n",
       " 'virgin olive oil',\n",
       " 'extra virgin olive oil',\n",
       " 'yellow',\n",
       " 'green onions',\n",
       " 'chicken breasts',\n",
       " 'green',\n",
       " 'sesame',\n",
       " 'wine',\n",
       " 'lime juice',\n",
       " 'corn',\n",
       " 'granulated sugar',\n",
       " 'ground pepper',\n",
       " 'coconut',\n",
       " 'spinach',\n",
       " 'ground beef',\n",
       " 'cayenne pepper',\n",
       " 'cornstarch',\n",
       " 'white sugar',\n",
       " 'wine vinegar',\n",
       " 'syrup',\n",
       " 'red onion',\n",
       " 'chili powder',\n",
       " 'rice',\n",
       " 'worcestershire sauce',\n",
       " 'ground cumin',\n",
       " 'mozzarella',\n",
       " 'orange juice',\n",
       " 'grated parmesan cheese',\n",
       " 'red wine',\n",
       " 'walnuts',\n",
       " 'chocolate chips',\n",
       " 'unsweetened',\n",
       " 'pasta',\n",
       " 'pepper flakes',\n",
       " 'minced garlic',\n",
       " 'temperature',\n",
       " 'almonds',\n",
       " 'sea salt',\n",
       " 'yogurt',\n",
       " 'canola',\n",
       " 'carrot',\n",
       " 'chicken stock',\n",
       " 'boneless skinless chicken',\n",
       " 'jalapeno',\n",
       " 'pecans',\n",
       " 'shrimp',\n",
       " 'red pepper flakes',\n",
       " 'wheat',\n",
       " 'dijon mustard',\n",
       " 'pineapple',\n",
       " 'lettuce',\n",
       " 'coriander',\n",
       " 'canola oil',\n",
       " 'dressing',\n",
       " 'chicken breast',\n",
       " 'rosemary',\n",
       " 'mozzarella cheese',\n",
       " 'raisins',\n",
       " 'powdered sugar',\n",
       " 'instant',\n",
       " 'buttermilk',\n",
       " 'sausage',\n",
       " 'red bell pepper',\n",
       " 'dried oregano',\n",
       " 'mushroom',\n",
       " 'sesame oil',\n",
       " 'roasted',\n",
       " 'scallions',\n",
       " 'cumin',\n",
       " 'semisweet chocolate',\n",
       " 'zucchini',\n",
       " 'whipping cream',\n",
       " 'apple',\n",
       " 'confectioners sugar',\n",
       " 'dry',\n",
       " 'crumbs',\n",
       " 'stock',\n",
       " 'peanut butter',\n",
       " 'freshly ground pepper',\n",
       " 'egg yolks',\n",
       " 'pork',\n",
       " 'red',\n",
       " 'cabbage',\n",
       " 'noodles',\n",
       " 'egg whites',\n",
       " 'chili',\n",
       " 'tomato sauce',\n",
       " 'tortillas',\n",
       " 'beef',\n",
       " 'tomato paste',\n",
       " 'chives',\n",
       " 'yeast',\n",
       " 'shortening',\n",
       " 'peas',\n",
       " 'fillets',\n",
       " 'lemon zest',\n",
       " 'olives',\n",
       " 'broccoli',\n",
       " 'cider vinegar',\n",
       " 'cooking spray',\n",
       " 'seeds',\n",
       " 'shallots',\n",
       " 'apples',\n",
       " 'balsamic vinegar',\n",
       " 'breadcrumbs',\n",
       " 'more',\n",
       " 'turkey',\n",
       " 'dry white wine',\n",
       " 'potato',\n",
       " 'green onion',\n",
       " 'prepared',\n",
       " 'light brown sugar',\n",
       " 'strawberries',\n",
       " 'bay leaves',\n",
       " 'dried thyme',\n",
       " 'ground ginger',\n",
       " 'bread crumbs',\n",
       " 'bay leaf',\n",
       " 'cocoa powder',\n",
       " 'lime',\n",
       " 'red wine vinegar',\n",
       " 'skinless chicken breasts',\n",
       " 'ketchup',\n",
       " 'green bell pepper',\n",
       " 'bay',\n",
       " 'black beans',\n",
       " 'pumpkin',\n",
       " 'ice',\n",
       " 'onion powder',\n",
       " 'nuts',\n",
       " 'oats',\n",
       " 'dill',\n",
       " 'allspice',\n",
       " 'boneless skinless chicken breasts',\n",
       " 'sesame seeds',\n",
       " 'green pepper',\n",
       " 'sweetened',\n",
       " 'bell peppers',\n",
       " 'basil leaves',\n",
       " 'ham',\n",
       " 'ground nutmeg',\n",
       " 'maple syrup',\n",
       " 'broth',\n",
       " 'bananas',\n",
       " 'white pepper',\n",
       " 'cucumber',\n",
       " 'jack cheese',\n",
       " 'yellow onion',\n",
       " 'chilies',\n",
       " 'turmeric',\n",
       " 'cake',\n",
       " 'cranberries',\n",
       " 'liquid',\n",
       " 'cold water',\n",
       " 'boiling water',\n",
       " 'monterey jack',\n",
       " 'peanut',\n",
       " 'avocado',\n",
       " 'wheat flour',\n",
       " 'cornmeal',\n",
       " 'hot sauce',\n",
       " 'blueberries',\n",
       " 'dried basil',\n",
       " 'a',\n",
       " 'shallot',\n",
       " 'mint',\n",
       " 'curry powder',\n",
       " 'sherry',\n",
       " 'bouillon',\n",
       " 'coconut milk',\n",
       " 'melted butter',\n",
       " 'mushroom soup',\n",
       " 'green beans',\n",
       " 'spaghetti',\n",
       " 'banana',\n",
       " 'ice cream',\n",
       " 'topping',\n",
       " 'corn syrup',\n",
       " 'chicken breast halves',\n",
       " 'parsley leaves',\n",
       " 'feta cheese',\n",
       " 'peppercorns',\n",
       " 'boneless chicken',\n",
       " 'halfandhalf',\n",
       " 'apple cider',\n",
       " 'half',\n",
       " 'semisweet chocolate chips',\n",
       " 'pastry',\n",
       " 'dry yeast',\n",
       " 'ricotta',\n",
       " 'salsa',\n",
       " 'white vinegar',\n",
       " 'roast',\n",
       " 'white rice',\n",
       " 'pure vanilla',\n",
       " 'cake mix',\n",
       " 'warm water',\n",
       " 'chips',\n",
       " 'rice vinegar',\n",
       " 'ground cloves',\n",
       " 'fennel',\n",
       " 'sharp cheddar cheese',\n",
       " 'molasses',\n",
       " 'pure vanilla extract',\n",
       " 'orange zest',\n",
       " 'condensed milk',\n",
       " 'cocoa',\n",
       " 'asparagus',\n",
       " 'cherry tomatoes',\n",
       " 'black olives',\n",
       " 'lemons',\n",
       " 'gelatin',\n",
       " 'cream of mushroom soup',\n",
       " 'monterey jack cheese',\n",
       " 'plain yogurt',\n",
       " 'tarragon',\n",
       " 'cooked chicken',\n",
       " 'dry mustard',\n",
       " 'salmon',\n",
       " 'whipped topping',\n",
       " 'crackers',\n",
       " 'almond extract',\n",
       " 'almond',\n",
       " 'ground coriander',\n",
       " 'steak',\n",
       " 'peanuts',\n",
       " 'cool whip',\n",
       " 'kidney',\n",
       " 'ricotta cheese',\n",
       " 'yolk',\n",
       " 'green chilies',\n",
       " 'pudding',\n",
       " 'raspberries',\n",
       " 'bottle',\n",
       " 'lean ground beef',\n",
       " 'garlic salt',\n",
       " 'egg yolk',\n",
       " 'beef broth',\n",
       " 'swiss cheese',\n",
       " 'dark brown sugar',\n",
       " 'low sodium',\n",
       " 'sage',\n",
       " 'hot water',\n",
       " 'flour tortillas',\n",
       " 'flavor',\n",
       " 'peanut oil',\n",
       " 'other',\n",
       " 'rum',\n",
       " 'coarse salt',\n",
       " 'kidney beans',\n",
       " 'plum tomatoes',\n",
       " 'capers',\n",
       " 'chiles',\n",
       " 'sweet potatoes',\n",
       " 'cherries',\n",
       " 'chipotle',\n",
       " 'vegetable broth',\n",
       " 'zest',\n",
       " 'whipped cream',\n",
       " 'sliced mushrooms',\n",
       " 'macaroni',\n",
       " 'white wine vinegar',\n",
       " 'crust',\n",
       " 'cardamom',\n",
       " 'liqueur',\n",
       " 'fish sauce',\n",
       " 'sweetened condensed milk',\n",
       " 'pine nuts',\n",
       " 'cilantro leaves',\n",
       " 'heavy whipping cream',\n",
       " 'meat',\n",
       " 'cake flour',\n",
       " 'mint leaves',\n",
       " 'strawberry',\n",
       " 'sodium',\n",
       " 'greens',\n",
       " 'baby spinach',\n",
       " 'italian seasoning',\n",
       " 'unbleached',\n",
       " 'grain',\n",
       " 'rolled oats',\n",
       " 'jalapeno pepper',\n",
       " 'apple cider vinegar',\n",
       " 'white chocolate',\n",
       " 'thyme leaves',\n",
       " 'cauliflower',\n",
       " 'cream of chicken soup',\n",
       " 'egg white',\n",
       " 'chicken thighs',\n",
       " 'active dry yeast',\n",
       " 'oranges',\n",
       " 'crosswise',\n",
       " 'beer',\n",
       " 'evaporated milk',\n",
       " 'pepper sauce',\n",
       " 'coffee',\n",
       " 'ground turkey',\n",
       " 'raspberry',\n",
       " 'white onion',\n",
       " 'cereal',\n",
       " 'vegetable stock',\n",
       " 'steaks',\n",
       " 'cherry',\n",
       " 'tofu',\n",
       " 'mix',\n",
       " 'stick butter',\n",
       " 'chickpeas',\n",
       " 'fat free',\n",
       " 'marshmallows',\n",
       " 'hot pepper',\n",
       " 'brandy',\n",
       " 'dried cranberries',\n",
       " 'brown rice',\n",
       " 'salad dressing',\n",
       " 'cottage cheese',\n",
       " 'lamb',\n",
       " 'sliced almonds',\n",
       " 'frozen peas',\n",
       " 'filling',\n",
       " 'taco seasoning',\n",
       " 'vegetables',\n",
       " 'flavored',\n",
       " 'rolls',\n",
       " 'romaine lettuce',\n",
       " 'minced onion',\n",
       " 'light corn syrup',\n",
       " 'red peppers',\n",
       " 'peaches',\n",
       " 'grated orange',\n",
       " 'hamburger',\n",
       " 'unsweetened cocoa powder',\n",
       " 'dough',\n",
       " 'arugula',\n",
       " 'white bread',\n",
       " 'sweet onion',\n",
       " 'rice wine',\n",
       " 'horseradish',\n",
       " 'freshly grated parmesan',\n",
       " 'skim milk',\n",
       " 'vodka',\n",
       " 'black peppercorns',\n",
       " 'barbecue sauce',\n",
       " 'limes',\n",
       " 'chili sauce',\n",
       " 'vanilla ice cream',\n",
       " 'dried parsley',\n",
       " 'cookies',\n",
       " 'sunflower',\n",
       " 'grated lemon zest',\n",
       " 'icing',\n",
       " 'chicken bouillon',\n",
       " 'corn tortillas',\n",
       " 'pineapple juice',\n",
       " 'frozen spinach',\n",
       " 'coloring',\n",
       " 'red bell peppers',\n",
       " 'greek yogurt',\n",
       " 'goat cheese',\n",
       " 'grated nutmeg',\n",
       " 'salad',\n",
       " 'apple juice',\n",
       " 'boneless chicken breast',\n",
       " 'red chili',\n",
       " 'blue cheese',\n",
       " 'bread flour',\n",
       " 'artichoke hearts',\n",
       " 'dark chocolate',\n",
       " 'cranberry',\n",
       " 'breast',\n",
       " 'ground pork',\n",
       " 'spinach leaves',\n",
       " 'food coloring',\n",
       " 'cream of tartar',\n",
       " 'applesauce',\n",
       " 'slivered almonds',\n",
       " 'sprouts',\n",
       " 'scallion',\n",
       " 'ground allspice',\n",
       " 'chile',\n",
       " 'cracked black pepper',\n",
       " 'blanched',\n",
       " 'saffron',\n",
       " 'flaked coconut',\n",
       " 'shells',\n",
       " 'bittersweet chocolate',\n",
       " 'ice cubes',\n",
       " 'celery ribs',\n",
       " 'fruit',\n",
       " 'butternut',\n",
       " 'concentrate',\n",
       " 'minced ginger',\n",
       " 'pork chops',\n",
       " 'hot pepper sauce',\n",
       " 'eggplant',\n",
       " 'tenderloin',\n",
       " 'beef stock',\n",
       " 'soup mix',\n",
       " 'minced parsley',\n",
       " 'pie crust',\n",
       " 'medium tomatoes',\n",
       " 'cucumbers',\n",
       " 'dry sherry',\n",
       " 'butternut squash',\n",
       " 'corn kernels',\n",
       " 'egg noodles',\n",
       " 'plain flour',\n",
       " 'lentils',\n",
       " 'masala',\n",
       " 'seasoning mix',\n",
       " 'avocados',\n",
       " 'preserves',\n",
       " 'garam masala',\n",
       " 'ground turmeric',\n",
       " 'tortilla chips',\n",
       " 'cooked rice',\n",
       " 'onion soup',\n",
       " 'sirloin',\n",
       " 'tuna',\n",
       " 'caster',\n",
       " 'mirin',\n",
       " 'marjoram',\n",
       " 'jalapenos',\n",
       " 'mango',\n",
       " 'sake',\n",
       " 'vegetable shortening',\n",
       " 'curry',\n",
       " 'apricot',\n",
       " 'caster sugar',\n",
       " 'prosciutto',\n",
       " 'italian sausage',\n",
       " 'leaf parsley',\n",
       " 'romano',\n",
       " 'dill weed',\n",
       " 'salt and ground black pepper',\n",
       " 'chunky',\n",
       " 'leeks',\n",
       " 'all-purpose flour',\n",
       " 'icing sugar',\n",
       " 'flat leaf parsley',\n",
       " 'soup',\n",
       " 'splenda',\n",
       " 'cracker crumbs',\n",
       " 'frozen corn',\n",
       " 'any',\n",
       " 'vinaigrette',\n",
       " 'broccoli florets',\n",
       " 'spice',\n",
       " 'sprig',\n",
       " 'pie filling',\n",
       " 'stuffing',\n",
       " 'dates',\n",
       " 'baguette',\n",
       " 'milk chocolate',\n",
       " 'serrano',\n",
       " 'cooking oil',\n",
       " 'yukon gold',\n",
       " 'seasoning salt',\n",
       " 'jalapeno peppers',\n",
       " 'boneless pork',\n",
       " 'kalamata',\n",
       " 'mustard seeds',\n",
       " 'chopped',\n",
       " 'spring',\n",
       " 'dry red wine',\n",
       " 'blend',\n",
       " 'pesto',\n",
       " 'chili pepper',\n",
       " 'pears',\n",
       " 'green bell peppers',\n",
       " 'lettuce leaves',\n",
       " 'paste',\n",
       " 'boneless skinless chicken breast halves',\n",
       " 'purple',\n",
       " 'dried rosemary',\n",
       " 'essence',\n",
       " 'puff pastry',\n",
       " 'french bread',\n",
       " 'raw',\n",
       " 'velveeta',\n",
       " 'roma tomatoes',\n",
       " 'onion soup mix',\n",
       " 'caramel',\n",
       " 'condensed cream',\n",
       " 'pecan',\n",
       " 'vanilla bean',\n",
       " 'in water',\n",
       " 'yellow bell pepper',\n",
       " 'american',\n",
       " 'romano cheese',\n",
       " 'light cream',\n",
       " 'chestnuts',\n",
       " 'philadelphia cream cheese',\n",
       " 'lemon peel',\n",
       " 'graham cracker crumbs',\n",
       " 'firm tofu',\n",
       " 'organic',\n",
       " 'anise',\n",
       " 'crabmeat',\n",
       " 'squash',\n",
       " 'instant coffee',\n",
       " 'apricots',\n",
       " 'low sodium chicken',\n",
       " 'pumpkin puree',\n",
       " 'caraway',\n",
       " 'salmon fillets',\n",
       " 'gingerroot',\n",
       " 'orange peel',\n",
       " 'medium shrimp',\n",
       " 'candy',\n",
       " 'natural',\n",
       " 'medium potatoes',\n",
       " 'soft',\n",
       " 'oyster',\n",
       " 'grapes',\n",
       " 'yellow mustard',\n",
       " 'leek',\n",
       " 'russet potatoes',\n",
       " 'maraschino',\n",
       " 'pistachios',\n",
       " 'creamy peanut butter',\n",
       " 'creme fraiche',\n",
       " 'smoked paprika',\n",
       " 'lemon rind',\n",
       " 'ranch dressing',\n",
       " 'ground cardamom',\n",
       " 'coconut oil',\n",
       " 'quinoa',\n",
       " 'boneless chicken breast halves',\n",
       " 'dried red',\n",
       " 'cinnamon sticks',\n",
       " 'cannellini',\n",
       " 'green olives',\n",
       " 'quick',\n",
       " 'ground red pepper',\n",
       " 'red kidney beans',\n",
       " 'bourbon',\n",
       " 'chili peppers',\n",
       " 'espresso',\n",
       " 'sundried tomatoes',\n",
       " 'gold potatoes',\n",
       " 'low sodium chicken broth',\n",
       " 'grape tomatoes',\n",
       " 'garbanzo',\n",
       " 'jelly',\n",
       " 'pecan halves',\n",
       " 'pork loin',\n",
       " 'elbow macaroni',\n",
       " 'yukon gold potatoes',\n",
       " 'hamburger buns',\n",
       " 'medium zucchini',\n",
       " 'watercress',\n",
       " 'pumpkin pie spice',\n",
       " 'yellow onions',\n",
       " 'sugar substitute',\n",
       " 'oatmeal',\n",
       " 'oregano leaves',\n",
       " 'herbs',\n",
       " 'button mushrooms',\n",
       " 'canned tomatoes',\n",
       " 'cashews',\n",
       " 'stewed tomatoes',\n",
       " 'yellow squash',\n",
       " 'ice water',\n",
       " 'sherry wine',\n",
       " 'baby carrots',\n",
       " 'bean sprouts',\n",
       " 'pinto beans',\n",
       " 'reduced fat',\n",
       " 'sriracha',\n",
       " 'fish',\n",
       " 'hazelnuts',\n",
       " 'scallops',\n",
       " 'asian',\n",
       " 'ginger root',\n",
       " 'basmati',\n",
       " 'pasta sauce',\n",
       " 'green peppers',\n",
       " 'garbanzo beans',\n",
       " 'barley',\n",
       " 'eggplants',\n",
       " 'ground white pepper',\n",
       " 'unsweetened chocolate',\n",
       " 'sunflower seeds',\n",
       " 'baking potatoes',\n",
       " 'pork sausage',\n",
       " 'beef bouillon',\n",
       " 'rice wine vinegar',\n",
       " 'peach',\n",
       " 'prepared mustard',\n",
       " 'kale',\n",
       " 'unsweetened coconut',\n",
       " 'blackberries',\n",
       " 'shiitake mushrooms',\n",
       " 'jello',\n",
       " 'egg substitute',\n",
       " 'golden raisins',\n",
       " 'penne pasta',\n",
       " 'hoisin sauce',\n",
       " 'white flour',\n",
       " 'dark rum',\n",
       " 'american cheese',\n",
       " 'walnut',\n",
       " 'couscous',\n",
       " 'water chestnuts',\n",
       " 'unflavored gelatin',\n",
       " 'lime zest',\n",
       " 'yellow cake mix',\n",
       " 'coriander seeds',\n",
       " 'tomato juice',\n",
       " 'radishes',\n",
       " 'low fat',\n",
       " 'berries',\n",
       " 'granny smith apples',\n",
       " 'vanilla pudding',\n",
       " 'beets',\n",
       " 'pork tenderloin',\n",
       " 'salted butter',\n",
       " 'butterscotch',\n",
       " 'celery seed',\n",
       " 'vidalia',\n",
       " 'flaked',\n",
       " 'rib',\n",
       " 'sweet potato',\n",
       " 'oyster sauce',\n",
       " 'champagne',\n",
       " 'starch',\n",
       " 'frosting',\n",
       " 'parsley flakes',\n",
       " 'rice flour',\n",
       " 'basmati rice',\n",
       " 'turkey breast',\n",
       " 'dried dill',\n",
       " 'firmly packed brown sugar',\n",
       " 'pepperoni',\n",
       " 'poppy seeds',\n",
       " 'salted',\n",
       " 'distilled',\n",
       " 'cannellini beans',\n",
       " 'new potatoes',\n",
       " 'stuffing mix',\n",
       " 'taco seasoning mix',\n",
       " 'graham crackers',\n",
       " 'tahini',\n",
       " 'pineapple chunks',\n",
       " 'salad greens',\n",
       " 'mixed vegetables',\n",
       " 'large eggs',\n",
       " 'linguine',\n",
       " 'provolone cheese',\n",
       " 'poblano',\n",
       " 'marinara sauce',\n",
       " 'pure maple syrup',\n",
       " 'whiskey',\n",
       " 'fennel seeds',\n",
       " 'sauerkraut',\n",
       " 'seasoned salt',\n",
       " 'tequila',\n",
       " 'gruyere cheese',\n",
       " 'sourdough',\n",
       " 'skinless chicken thighs',\n",
       " 'low sodium soy sauce',\n",
       " 'green cabbage',\n",
       " 'curry paste',\n",
       " 'extra-virgin olive oil',\n",
       " 'lasagna noodles',\n",
       " 'juice concentrate',\n",
       " 'sausages',\n",
       " 'cooked ham',\n",
       " 'kalamata olives',\n",
       " 'chocolate syrup',\n",
       " 'cookie',\n",
       " 'wheat bread',\n",
       " 'marmalade',\n",
       " 'spring onions',\n",
       " 'purple onion',\n",
       " 'pie shell',\n",
       " 'pork shoulder',\n",
       " 'light soy sauce',\n",
       " 'rounds',\n",
       " 'dry bread crumbs',\n",
       " 'shiitake',\n",
       " 'celery salt',\n",
       " 'chicken wings',\n",
       " 'agave nectar',\n",
       " 'adobo',\n",
       " 'prepared horseradish',\n",
       " 'cumin seed',\n",
       " 'ears',\n",
       " 'bisquick',\n",
       " 'lime wedges',\n",
       " 'cajun seasoning',\n",
       " 'iceberg lettuce',\n",
       " 'raisin',\n",
       " 'roasted red peppers',\n",
       " 'clams',\n",
       " 'peppermint',\n",
       " 'currants',\n",
       " 'tomato puree',\n",
       " 'green peas',\n",
       " 'italian bread',\n",
       " 'mussels',\n",
       " 'red chile',\n",
       " 'corn oil',\n",
       " 'orange rind',\n",
       " 'tomato soup',\n",
       " 'watermelon',\n",
       " 'fine sea salt',\n",
       " 'white beans',\n",
       " 'star anise',\n",
       " 'poultry seasoning',\n",
       " 'maraschino cherries',\n",
       " 'lemon pepper',\n",
       " 'tapioca',\n",
       " 'cold milk',\n",
       " 'baby spinach leaves',\n",
       " 'pancetta',\n",
       " 'yellow cornmeal',\n",
       " 'rhubarb',\n",
       " 'lemongrass',\n",
       " 'marshmallow',\n",
       " 'refried beans',\n",
       " 'toasted sesame oil',\n",
       " 'crab meat',\n",
       " 'chuck',\n",
       " 'flavoring',\n",
       " 'pomegranate',\n",
       " 'corn starch',\n",
       " 'orange marmalade',\n",
       " 'pear',\n",
       " 'penne',\n",
       " 'mascarpone',\n",
       " 'skin',\n",
       " 'red cabbage',\n",
       " 'sprinkles',\n",
       " 'stew meat',\n",
       " 'pickles',\n",
       " 'toasted sesame seeds',\n",
       " 'frozen broccoli',\n",
       " 'sliced green onions',\n",
       " 'mashed potatoes',\n",
       " 'cranberry juice',\n",
       " 'anchovy fillets',\n",
       " 'sage leaves',\n",
       " 'hot chili',\n",
       " 'white chocolate chips',\n",
       " 'parsnips',\n",
       " 'enchilada sauce',\n",
       " 'chile powder',\n",
       " 'fresh ginger',\n",
       " 'liquid smoke',\n",
       " 'arborio rice',\n",
       " 'sweet paprika',\n",
       " 'fennel bulb',\n",
       " 'dried apricots',\n",
       " 'unsweetened applesauce',\n",
       " 'chunky salsa',\n",
       " 'pizza sauce',\n",
       " 'onion flakes',\n",
       " 'distilled white vinegar',\n",
       " 'rosemary leaves',\n",
       " 'smoked ham',\n",
       " 'zesty italian dressing',\n",
       " 'bok choy',\n",
       " 'wild rice',\n",
       " 'boneless skinless chicken thighs',\n",
       " 'snow peas',\n",
       " 'saffron threads',\n",
       " 'cranberry sauce',\n",
       " 'green chiles',\n",
       " 'cheese blend',\n",
       " 'roasted peanuts',\n",
       " 'caraway seeds',\n",
       " 'sherry vinegar',\n",
       " 'jalapeno chilies',\n",
       " 'vermouth',\n",
       " 'soymilk',\n",
       " 'cherry pie filling',\n",
       " 'habanero',\n",
       " 'port',\n",
       " 'chopped cilantro',\n",
       " 'buns',\n",
       " 'agave',\n",
       " 'cooked turkey',\n",
       " 'vanilla yogurt',\n",
       " 'superfine sugar',\n",
       " 'head cauliflower',\n",
       " 'pumpkin seeds',\n",
       " 'duck',\n",
       " 'ancho',\n",
       " 'grape',\n",
       " 'grated lemon peel',\n",
       " 'lowfat yogurt',\n",
       " 'mandarin oranges',\n",
       " 'grapeseed oil',\n",
       " 'vanilla essence',\n",
       " 'wheat germ',\n",
       " 'diced tomatoes',\n",
       " 'brown mustard',\n",
       " 'cooked bacon',\n",
       " 'biscuits',\n",
       " 'panko breadcrumbs',\n",
       " 'mustard powder',\n",
       " 'apricot preserves',\n",
       " 'long grain rice',\n",
       " 'tomatillos',\n",
       " 'green chile',\n",
       " 'salad oil',\n",
       " 'corn flour',\n",
       " 'crisco',\n",
       " 'frozen whipped topping',\n",
       " 'spices',\n",
       " 'lard',\n",
       " 'cooked white rice',\n",
       " 'smooth',\n",
       " 'sundried tomato',\n",
       " 'with skin',\n",
       " 'softened butter',\n",
       " 'asiago',\n",
       " 'simple syrup',\n",
       " 'italian salad dressing',\n",
       " 'club soda',\n",
       " 'gin',\n",
       " 'root',\n",
       " 'coating',\n",
       " 'baking mix',\n",
       " 'roasted garlic',\n",
       " 'granulated garlic',\n",
       " 'amaretto',\n",
       " 'oreo',\n",
       " 'nonfat yogurt',\n",
       " 'vinaigrette dressing',\n",
       " 'pastry flour',\n",
       " 'fine salt',\n",
       " 'gluten',\n",
       " 'sliced black olives',\n",
       " 'condensed cream of mushroom soup',\n",
       " 'thyme sprigs',\n",
       " 'fat',\n",
       " 'cream of celery soup',\n",
       " 'popcorn',\n",
       " 'rotini',\n",
       " 'grapefruit',\n",
       " 'ground chuck',\n",
       " 'ground chicken',\n",
       " 'lobster',\n",
       " 'nonfat milk',\n",
       " 'crumbles',\n",
       " 'florets',\n",
       " 'dinner rolls',\n",
       " 'cremini',\n",
       " 'flank steak',\n",
       " 'catsup',\n",
       " 'flax seed',\n",
       " 'adobo sauce',\n",
       " 'dried onion',\n",
       " 'table salt',\n",
       " 'unsweetened coconut milk',\n",
       " 'okra',\n",
       " 'fish fillets',\n",
       " 'almond milk',\n",
       " 'season',\n",
       " 'chipotle chile',\n",
       " 'red food coloring',\n",
       " 'plums',\n",
       " 'corn flakes',\n",
       " 'grated orange peel',\n",
       " 'halibut',\n",
       " 'fresh parsley',\n",
       " 'salami',\n",
       " 'soy milk',\n",
       " 'gorgonzola',\n",
       " 'blanched almonds',\n",
       " 'blue',\n",
       " 'pistachio',\n",
       " 'croutons',\n",
       " 'fennel seed',\n",
       " 'pickle relish',\n",
       " 'wholewheat',\n",
       " 'herb',\n",
       " 'brisket',\n",
       " 'chile peppers',\n",
       " 'mini marshmallows',\n",
       " 'crumbled blue cheese',\n",
       " 'milk powder',\n",
       " 'glaze',\n",
       " 'pancake',\n",
       " 'brussels sprouts',\n",
       " 'sunflower oil',\n",
       " 'plum',\n",
       " 'leaf lettuce',\n",
       " 'cardamom pods',\n",
       " 'dried cherries',\n",
       " 'savory',\n",
       " 'grand marnier',\n",
       " 'fontina',\n",
       " 'smoked salmon',\n",
       " 'asparagus spears',\n",
       " 'kraft grated parmesan cheese',\n",
       " 'prunes',\n",
       " 'bacon bits',\n",
       " 'cheese spread',\n",
       " 'chuck roast',\n",
       " 'accompaniment',\n",
       " 'fresh lemon',\n",
       " 'dry milk',\n",
       " ...]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ingss = list(pd.read_csv('/home/ashvinee/Documents/Ferrato/Data/all_ingredients_name.csv')['In'])\n",
    "all_ingss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e69f0ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing_len = len(all_ingss)\n",
    "new_arr = np.zeros(ing_len).astype(int)\n",
    "new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b510481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de25f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in aab:\n",
    "    ing_str = item.replace(\" \", \"\")\n",
    "    indx = all_ingss.index(ing_str)\n",
    "    new_arr[indx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f83d186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e992b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3501,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr = np.array([0]+list(new_arr)).astype(int)\n",
    "#new_arr = torch.from_numpy(new_arr)\n",
    "new_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5da73994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(853, 3501)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = features[:853,:]\n",
    "feat = feat.cpu().detach().numpy()\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c7c089f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2],[3,4]]+[[5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a952247",
   "metadata": {},
   "outputs": [],
   "source": [
    "liss = []\n",
    "for i in feat:\n",
    "    liss.append([int(j) for j in list(i)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84089578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([854, 3501])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featt = np.array([list(new_arr)]+liss)\n",
    "new_featt = torch.from_numpy(featt)\n",
    "new_featt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ad95554",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFeat = sp.csr_matrix(new_featt, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "89939ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = torch.FloatTensor(np.array(TFeat.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56ac4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(feats, adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fd43dda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3693, -1.1751],\n",
       "        [-0.3693, -1.1751],\n",
       "        [-0.3693, -1.1751],\n",
       "        ...,\n",
       "        [-0.3693, -1.1751],\n",
       "        [-0.3693, -1.1751],\n",
       "        [-0.3693, -1.1751]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84f03121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3693, -1.1751], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5d133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
